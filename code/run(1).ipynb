{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/meti-94/CodeOceanBERTQA.git -q\n",
        "%cd CodeOceanBERTQA/code/"
      ],
      "metadata": {
        "id": "qaTgOdic_DAx",
        "outputId": "40f47fce-4064-4172-9518-0ddbaa3d08cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qaTgOdic_DAx",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeOceanBERTQA/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip uninstall -y torchtext -q\n",
        "!pip install torchtext==0.2.3 -q\n",
        "!pip install pytorch-crf==0.7.2 -q"
      ],
      "metadata": {
        "id": "16r8uYp2_m4h"
      },
      "id": "16r8uYp2_m4h",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf91d035",
      "metadata": {
        "id": "bf91d035"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from data import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f00800",
      "metadata": {
        "id": "19f00800"
      },
      "outputs": [],
      "source": [
        "# check if Bertified data exists\n",
        "if not os.path.isfile('../data/Bertified/entities.npy'):\n",
        "    reverb_lines = read_reverb('../data/Reverb1.1/reverb_wikipedia_tuples-1.1.txt')\n",
        "    questions = pd.read_excel('../data/ReverbSQA/Final_Sheet_990824.xlsx', sheet_name=1, engine='openpyxl')\n",
        "    index = get_tuple_frequency(reverb_lines, questions)\n",
        "    index[index['Frequency']<10].to_excel('../data/ProcessedQuestions/normalized_questions.xlsx')\n",
        "    combine_with_reverb(questions_path='../data/ProcessedQuestions/normalized_questions.xlsx', \n",
        "                    reverb_path='../data/Reverb1.1/reverb_wikipedia_tuples-1.1.txt')\n",
        "    create_bertified_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4740e484",
      "metadata": {
        "id": "4740e484",
        "outputId": "7bd513af-8a40-479c-f5b9-9cd6bcbebe6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 triple  \\\n",
              "8639  ('Charlene Choi', 'was educated at', 'a number...   \n",
              "4206              ('Quinn', 'left the show in', '2000')   \n",
              "9211                   ('Clowers', 'died in', 'Sweeny')   \n",
              "2217   ('Donaldson', 'was born in', 'Poulton-le-Fylde')   \n",
              "6685    ('Kucinich', 'campaigned heavily in', 'Oregon')   \n",
              "3247      ('Carthage', 'is a city in', 'Panola County')   \n",
              "\n",
              "                                          Question  \n",
              "8639  who was educated at a number of institutions  \n",
              "4206               When did Quinn leave the show    \n",
              "9211                          where Clowers died    \n",
              "2217             who  was born in Poulton-le-Fylde  \n",
              "6685              who campaigned heavily in Oregon  \n",
              "3247                 What city is in Panola County  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-459ebb49-1d54-485f-b644-6fcc55b3f022\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>triple</th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8639</th>\n",
              "      <td>('Charlene Choi', 'was educated at', 'a number...</td>\n",
              "      <td>who was educated at a number of institutions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4206</th>\n",
              "      <td>('Quinn', 'left the show in', '2000')</td>\n",
              "      <td>When did Quinn leave the show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9211</th>\n",
              "      <td>('Clowers', 'died in', 'Sweeny')</td>\n",
              "      <td>where Clowers died</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2217</th>\n",
              "      <td>('Donaldson', 'was born in', 'Poulton-le-Fylde')</td>\n",
              "      <td>who  was born in Poulton-le-Fylde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6685</th>\n",
              "      <td>('Kucinich', 'campaigned heavily in', 'Oregon')</td>\n",
              "      <td>who campaigned heavily in Oregon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3247</th>\n",
              "      <td>('Carthage', 'is a city in', 'Panola County')</td>\n",
              "      <td>What city is in Panola County</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-459ebb49-1d54-485f-b644-6fcc55b3f022')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-459ebb49-1d54-485f-b644-6fcc55b3f022 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-459ebb49-1d54-485f-b644-6fcc55b3f022');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# table 1 output \n",
        "pd.read_excel('../data/Intermediate/train.xlsx').sample(6)[['triple', 'Question']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b66aec",
      "metadata": {
        "id": "41b66aec",
        "outputId": "63b2731a-aff9-404f-fbe5-9c5e1d21e435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Triples\t:\t407236\n",
            "#Relations\t:\t101977\n",
            "#Entity 1\t:\t182329\n",
            "#Entity 2\t:\t156166\n",
            "Total Unique Entities\t:\t304853\n",
            "Vocabulary Size\t:\t148953\n"
          ]
        }
      ],
      "source": [
        "# table 2 output\n",
        "df = pd.read_csv(r'../data/Reverb1.1/reverb_wikipedia_tuples-1.1.txt', sep='\\t', header=None)\n",
        "reverb_columns_name = ['ExID', 'arg1', 'rel', 'arg2', 'narg1', 'nrel', 'narg2', 'csents', 'conf', 'urls']\n",
        "df.columns = reverb_columns_name\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(f'#Triples\\t:\\t{len(df)}')\n",
        "print(f'#Relations\\t:\\t{len(df[\"rel\"].unique())}')\n",
        "print(f'#Entity 1\\t:\\t{len(df[\"arg1\"].unique())}')\n",
        "print(f'#Entity 2\\t:\\t{len(df[\"arg2\"].unique())}')\n",
        "print(f'Total Unique Entities\\t:\\t{len(set(df[\"arg1\"].unique().tolist()+df[\"arg2\"].unique().tolist()))}')\n",
        "vocab = df[\"arg1\"].unique().tolist()+df[\"arg2\"].unique().tolist()+df[\"rel\"].unique().tolist()\n",
        "vocab = list(map(lambda x:x.split(), vocab))\n",
        "vocab = [item for sublist in vocab for item in sublist]\n",
        "print(f'Vocabulary Size\\t:\\t{len(set(vocab))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11e164e",
      "metadata": {
        "id": "f11e164e",
        "outputId": "0d03685c-01e5-4108-9ded-219ba3ddf8dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Training ***\n",
            "Number of Questions\t:\t9921\n",
            "Entity 1\t:\t6549\n",
            "Entity 2\t:\t5971\n",
            "Relations\t:\t4568\n",
            "Total Unique Entities\t:\t12155\n",
            "Unique Words\t:\t10123\n",
            "\n",
            "*** Validation ***\n",
            "Number of Questions\t:\t1751\n",
            "Entity 1\t:\t1624\n",
            "Entity 2\t:\t1566\n",
            "Relations\t:\t1297\n",
            "Total Unique Entities\t:\t3147\n",
            "Unique Words\t:\t2958\n",
            "\n",
            "*** Test ***\n",
            "Number of Questions\t:\t5003\n",
            "Entity 1\t:\t4064\n",
            "Entity 2\t:\t3827\n",
            "Relations\t:\t2939\n",
            "Total Unique Entities\t:\t7702\n",
            "Unique Words\t:\t6314\n"
          ]
        }
      ],
      "source": [
        "# table 3 output\n",
        "train_df = pd.read_excel('../data/Intermediate/train.xlsx'); valid_df = pd.read_excel('../data/Intermediate/valid.xlsx'); test_df = pd.read_excel('../data/Intermediate/test.xlsx')\n",
        "\n",
        "\n",
        "def get_unique_ent_rel(dataframe):\n",
        "    arg1 = [eval(item)[0] for item in dataframe['triple'].to_list()]\n",
        "    arg2 = [eval(item)[2] for item in dataframe['triple'].to_list()]\n",
        "    rel = [eval(item)[1] for item in dataframe['triple'].to_list()]\n",
        "    print(f'Number of Questions\\t:\\t{len(dataframe)}')\n",
        "    print(f'Entity 1\\t:\\t{len(set(arg1))}')\n",
        "    print(f'Entity 2\\t:\\t{len(set(arg2))}')\n",
        "    print(f'Relations\\t:\\t{len(set(rel))}')\n",
        "    print(f'Total Unique Entities\\t:\\t{len(set(arg1+arg2))}')\n",
        "    tokenizer = lambda string:string.strip().lower().split()\n",
        "    tokenized_questions = dataframe['Question'].astype(str).apply(tokenizer).to_list()\n",
        "    flatten_tokenized_questions = [item for sublist in tokenized_questions for item in sublist]\n",
        "    print(f'Unique Words\\t:\\t{len(set(flatten_tokenized_questions))}')\n",
        "\n",
        "print(\"*** Training ***\")\n",
        "get_unique_ent_rel(train_df)\n",
        "print(\"\\n*** Validation ***\")\n",
        "get_unique_ent_rel(valid_df)\n",
        "print(\"\\n*** Test ***\")\n",
        "get_unique_ent_rel(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a1f3e9",
      "metadata": {
        "id": "25a1f3e9",
        "outputId": "9c8ee33f-fbb5-4100-c3ba-88034e8b76d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for training\n",
            "Embedding match number 8546 out of 13972\n",
            "Shift model to GPU\n",
            "Namespace(entity_detection_mode='GRU', cuda=True, gpu=0, epochs=30, batch_size=256, dataset='EntityDetection', lr=0.0001, seed=3435, dev_every=2000, log_every=1000, patience=10, save_path='saved_checkpoints', specify_prefix='id1', words_dim=300, num_layer=2, rnn_fc_dropout=0.3, input_size=300, hidden_size=300, rnn_dropout=0.3, clip_gradient=0.6, vector_cache='../data/Cache/sq_glove300d.pt', weight_decay=0, train_embed=False, hits=100, trained_model='', data_dir='../data/SimpleQuestionNotationEntity', results_path='query_text', words_num=13972, label=4)\n",
            "VOCAB num 13972\n",
            "Train instance 9921\n",
            "Dev instance 1751\n",
            "Test instance 5003\n",
            "Entity Type 4\n",
            "EntityDetection(\n",
            "  (embed): Embedding(13972, 300)\n",
            "  (gru): GRU(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (hidden2tag): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=600, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
            "     1     1         1     1/39          3% 1.580225          0.0             \n",
            "    30    26      1001    26/39         67% 0.087461          65.44471153846153             \n",
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "Dev Precision:  80.558723% Recall:  80.284091% F1 Score:  80.421172%\n",
            "    61    52      2001    12/39         31% 0.059545          75.84635416666667             \n",
            "    91    77      3001    37/39         95% 0.032961          84.93454391891892             \n",
            "Dev Precision:  74.010327% Recall:  73.295455% F1 Score:  73.651156%\n",
            "   122   103      4001    23/39         59% 0.016462          91.5930706521739             \n",
            "   152   129      5001     9/39         23% 0.009022          95.48611111111111             \n",
            "Dev Precision:  75.228311% Recall:  74.886364% F1 Score:  75.056948%\n",
            "   183   154      6001    34/39         87% 0.010030          96.51884191176471             \n",
            "   213   180      7001    20/39         51% 0.007960          97.51953125             \n",
            "Dev Precision:  78.720996% Recall:  79.034091% F1 Score:  78.877233%\n",
            "   243   206      8001     6/39         15% 0.006092          97.65625             \n",
            "   273   231      9001    31/39         79% 0.005491          98.58870967741936             \n",
            "Dev Precision:  76.738883% Recall:  76.477273% F1 Score:  76.607854%\n",
            "   303   257     10001    17/39         44% 0.003010          98.46047794117646             \n",
            "   334   283     11001     3/39          8% 0.003540          98.30729166666667             \n",
            "Dev Precision:  73.684211% Recall:  73.181818% F1 Score:  73.432155%\n",
            "   364   308     12001    28/39         72% 0.001893          98.81417410714286             \n",
            "   394   334     13001    14/39         36% 0.004009          99.27455357142857             \n",
            "Dev Precision:  75.213675% Recall:  75.000000% F1 Score:  75.106686%\n",
            "   424   359     14001    39/39        100% 0.002509          99.08275375466182             \n",
            "   454   385     15001    25/39         64% 0.000681          98.90625             \n",
            "Dev Precision:  75.000000% Recall:  74.829545% F1 Score:  74.914676%\n",
            "   485   411     16001    11/39         28% 0.004758          98.79261363636364             \n",
            "   515   436     17001    36/39         92% 0.000898          99.30555555555556             \n",
            "Dev Precision:  71.697039% Recall:  71.534091% F1 Score:  71.615472%\n",
            "   545   462     18001    22/39         56% 0.001532          99.3075284090909             \n",
            "   575   488     19001     8/39         21% 0.000655          99.560546875             \n",
            "Dev Precision:  74.095348% Recall:  73.295455% F1 Score:  73.693231%\n",
            "   606   513     20001    33/39         85% 0.000614          99.33712121212122             \n",
            "   636   539     21001    19/39         49% 0.002346          99.17763157894737             \n",
            "Dev Precision:  77.677054% Recall:  77.897727% F1 Score:  77.787234%\n",
            "   667   565     22001     5/39         13% 0.001182          99.140625             \n",
            "   698   590     23001    30/39         77% 0.001311          99.4140625             \n",
            "Dev Precision:  74.871208% Recall:  74.318182% F1 Score:  74.593670%\n",
            "Early Stopping. Epoch: 616, Best Dev F1: 0.8042117245304498\n",
            "Test Precision:  76.336792% Recall:  76.048499% F1 Score:  76.192373%\n"
          ]
        }
      ],
      "source": [
        "# table 5 output {GRU's row}\n",
        "!python ./BuboQA/entities/train.py  --entity_detection_mode GRU \\\n",
        "                                    --fix_embed --data_dir ../data/SimpleQuestionNotationEntity \\\n",
        "                                    --batch_size 256 \\\n",
        "                                    --vector_cache ../data/Cache/sq_glove300d.pt \\\n",
        "                        \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# table 5 output {LSTM's row}\n",
        "!python ./BuboQA/entities/train.py  --entity_detection_mode LSTM \\\n",
        "                                    --fix_embed --data_dir ../data/SimpleQuestionNotationEntity \\\n",
        "                                    --batch_size 256 \\\n",
        "                                    --vector_cache ../data/Cache/sq_glove300d.pt \\\n",
        "                        \n"
      ],
      "metadata": {
        "id": "XK8ADMHTDkUX",
        "outputId": "c470b357-55e6-4a9a-9c8c-5a5ebfaf09b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XK8ADMHTDkUX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for training\n",
            "Embedding match number 8546 out of 13972\n",
            "Shift model to GPU\n",
            "Namespace(entity_detection_mode='LSTM', cuda=True, gpu=0, epochs=30, batch_size=256, dataset='EntityDetection', lr=0.0001, seed=3435, dev_every=2000, log_every=1000, patience=10, save_path='saved_checkpoints', specify_prefix='id1', words_dim=300, num_layer=2, rnn_fc_dropout=0.3, input_size=300, hidden_size=300, rnn_dropout=0.3, clip_gradient=0.6, vector_cache='../data/Cache/sq_glove300d.pt', weight_decay=0, train_embed=False, hits=100, trained_model='', data_dir='../data/SimpleQuestionNotationEntity', results_path='query_text', words_num=13972, label=4)\n",
            "VOCAB num 13972\n",
            "Train instance 9921\n",
            "Dev instance 1751\n",
            "Test instance 5003\n",
            "Entity Type 4\n",
            "EntityDetection(\n",
            "  (embed): Embedding(13972, 300)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (hidden2tag): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=600, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
            "     0     1         1     1/39          3% 1.691219          0.0             \n",
            "    40    26      1001    26/39         67% 0.089202          65.53485576923077             \n",
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "Dev Precision:  79.363275% Recall:  79.318182% F1 Score:  79.340722%\n",
            "    78    52      2001    12/39         31% 0.050130          77.44140625             \n",
            "   117    77      3001    37/39         95% 0.027996          87.39442567567568             \n",
            "Dev Precision:  73.556059% Recall:  73.806818% F1 Score:  73.681225%\n",
            "   156   103      4001    23/39         59% 0.017807          91.9836956521739             \n",
            "   194   129      5001     9/39         23% 0.007786          95.83333333333333             \n",
            "Dev Precision:  76.704545% Recall:  76.704545% F1 Score:  76.704545%\n",
            "   233   154      6001    34/39         87% 0.008491          96.12821691176471             \n",
            "   271   180      7001    20/39         51% 0.005190          97.7734375             \n",
            "Dev Precision:  77.005650% Recall:  77.443182% F1 Score:  77.223796%\n",
            "   310   206      8001     6/39         15% 0.006018          97.39583333333333             \n",
            "   348   231      9001    31/39         79% 0.003827          98.4375             \n",
            "Dev Precision:  73.219373% Recall:  73.011364% F1 Score:  73.115220%\n",
            "   387   257     10001    17/39         44% 0.001631          98.20772058823529             \n",
            "   425   283     11001     3/39          8% 0.002111          99.21875             \n",
            "Dev Precision:  76.931818% Recall:  76.931818% F1 Score:  76.931818%\n",
            "   464   308     12001    28/39         72% 0.002773          99.17689732142857             \n",
            "   502   334     13001    14/39         36% 0.002541          98.46540178571429             \n",
            "Dev Precision:  76.668568% Recall:  76.363636% F1 Score:  76.515798%\n",
            "   541   359     14001    39/39        100% 0.002770          98.81060376978127             \n",
            "   580   385     15001    25/39         64% 0.001496          98.859375             \n",
            "Dev Precision:  73.883162% Recall:  73.295455% F1 Score:  73.588135%\n",
            "   619   411     16001    11/39         28% 0.000870          99.14772727272727             \n",
            "   657   436     17001    36/39         92% 0.002812          99.05598958333333             \n",
            "Dev Precision:  77.689243% Recall:  77.556818% F1 Score:  77.622974%\n",
            "   695   462     18001    22/39         56% 0.002477          99.0234375             \n",
            "   734   488     19001     8/39         21% 0.000628          99.31640625             \n",
            "Dev Precision:  77.576444% Recall:  77.840909% F1 Score:  77.708452%\n",
            "   772   513     20001    33/39         85% 0.000360          99.43181818181819             \n",
            "   811   539     21001    19/39         49% 0.002096          99.3626644736842             \n",
            "Dev Precision:  76.168757% Recall:  75.909091% F1 Score:  76.038702%\n",
            "   849   565     22001     5/39         13% 0.000621          99.140625             \n",
            "   887   590     23001    30/39         77% 0.001198          98.42447916666667             \n",
            "Dev Precision:  77.928693% Recall:  78.238636% F1 Score:  78.083357%\n",
            "Early Stopping. Epoch: 616, Best Dev F1: 0.7934072179596477\n",
            "Test Precision:  79.230311% Recall:  79.387796% F1 Score:  79.308975%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# table 6 output {LSTM's row}\n",
        "!python ./BuboQA/relations/train.py  --relation_prediction_mode LSTM \\\n",
        "                                     --fix_embed --data_dir ../data/SimpleQuestionNotationRelation \\\n",
        "                                     --batch_size 256 \\\n",
        "                                     --vector_cache ../data/Cache/sq_glove300d.pt "
      ],
      "metadata": {
        "id": "dvL0CuT8AmIt",
        "outputId": "c1bc0651-2b88-4738-94a3-aabe567e1b07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dvL0CuT8AmIt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for training\n",
            "Embedding match number 8546 out of 13972\n",
            "Shift model to GPU\n",
            "Namespace(relation_prediction_mode='LSTM', cuda=True, gpu=0, epochs=30, batch_size=256, dataset='RelationPrediction', mode='static', lr=0.0001, seed=3435, dev_every=2000, log_every=1000, patience=10, save_path='saved_checkpoints', specify_prefix='id1', output_channel=300, words_dim=300, num_layer=2, rnn_dropout=0.3, input_size=300, hidden_size=300, rnn_fc_dropout=0.3, clip_gradient=0.6, vector_cache='../data/Cache/sq_glove300d.pt', weight_decay=0, cnn_dropout=0.5, train_embed=False, hits=5, data_dir='../data/SimpleQuestionNotationRelation', trained_model='', results_path='results', words_num=13972, rel_label=4236)\n",
            "VOCAB num 13972\n",
            "Train instance 9922\n",
            "Dev instance 1752\n",
            "Test instance 5004\n",
            "Relation Type 4236\n",
            "RelationPrediction(\n",
            "  (embed): Embedding(13972, 300)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (hidden2tag): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=600, out_features=4236, bias=True)\n",
            "  )\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
            "     0     1         1     1/39          3% 8.530475          0.0             \n",
            "    32    26      1001    26/39         67% 2.149116          72.8515625             \n",
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "Dev Precision:  37.842466%\n",
            "    62    52      2001    12/39         31% 0.310667          96.875             \n",
            "    92    77      3001    37/39         95% 0.089844          99.64105224609375             \n",
            "Dev Precision:  41.552511%\n",
            "   122   103      4001    23/39         59% 0.040190          99.88111877441406             \n",
            "   152   129      5001     9/39         23% 0.013308          99.86978912353516             \n",
            "Dev Precision:  41.837900%\n",
            "   182   154      6001    34/39         87% 0.009180          99.9195785522461             \n",
            "   213   180      7001    20/39         51% 0.004918          99.98046875             \n",
            "Dev Precision:  42.066210%\n",
            "   243   206      8001     6/39         15% 0.002382          100.0             \n",
            "   273   231      9001    31/39         79% 0.001518          99.91178894042969             \n",
            "Dev Precision:  42.636986%\n",
            "   303   257     10001    17/39         44% 0.000956          99.83915710449219             \n",
            "   333   283     11001     3/39          8% 0.009781          99.86979675292969             \n",
            "Dev Precision:  42.808219%\n",
            "   363   308     12001    28/39         72% 0.000523          99.90235137939453             \n",
            "   393   334     13001    14/39         36% 0.000518          99.91629791259766             \n",
            "Dev Precision:  42.522831%\n",
            "   424   359     14001    39/39        100% 0.000237          99.89920806884766             \n",
            "   454   385     15001    25/39         64% 0.000177          99.9375             \n",
            "Dev Precision:  43.436073%\n",
            "   484   411     16001    11/39         28% 0.000139          99.96449279785156             \n",
            "   514   436     17001    36/39         92% 0.000165          99.93489837646484             \n",
            "Dev Precision:  43.321918%\n",
            "   544   462     18001    22/39         56% 0.004114          99.94673919677734             \n",
            "   574   488     19001     8/39         21% 0.000108          99.90234375             \n",
            "Dev Precision:  43.093607%\n",
            "   604   513     20001    33/39         85% 0.000054          99.9408187866211             \n",
            "   634   539     21001    19/39         49% 0.000171          99.9588851928711             \n",
            "Dev Precision:  42.522831%\n",
            "   664   565     22001     5/39         13% 0.000068          99.84375             \n",
            "   695   590     23001    30/39         77% 0.000044          99.89583587646484             \n",
            "Dev Precision:  42.180365%\n",
            "   725   616     24001    16/39         41% 0.004293          99.90234375             \n",
            "   755   642     25001     2/39          5% 0.005775          99.8046875             \n",
            "Dev Precision:  42.408676%\n",
            "   785   667     26001    27/39         69% 0.000219          99.91319274902344             \n",
            "   815   693     27001    13/39         33% 0.000109          99.90985870361328             \n",
            "Dev Precision:  42.408676%\n",
            "   845   718     28001    38/39         97% 0.000063          99.92804718017578             \n",
            "   875   744     29001    24/39         62% 0.000047          99.951171875             \n",
            "Dev Precision:  42.865297%\n",
            "   905   770     30001    10/39         26% 0.000041          99.9609375             \n",
            "   935   795     31001    35/39         90% 0.000467          99.91071319580078             \n",
            "Dev Precision:  42.808219%\n",
            "   966   821     32001    21/39         54% 0.000033          99.92559814453125             \n",
            "   996   847     33001     7/39         18% 0.000020          99.94419860839844             \n",
            "Dev Precision:  43.493151%\n",
            "  1026   872     34001    32/39         82% 0.000012          99.9267578125             \n",
            "  1056   898     35001    18/39         46% 0.000013          99.91319274902344             \n",
            "Dev Precision:  42.636986%\n",
            "  1086   924     36001     4/39         10% 0.000041          99.90234375             \n",
            "  1117   949     37001    29/39         74% 0.004824          99.90570831298828             \n",
            "Dev Precision:  42.694064%\n",
            "  1147   975     38001    15/39         38% 0.000015          99.94792175292969             \n",
            "  1177  1001     39001     1/39          3% 0.000080          100.0             \n",
            "Dev Precision:  42.636986%\n",
            "  1207  1026     40001    26/39         67% 0.000016          99.96995544433594             \n",
            "  1238  1052     41001    12/39         31% 0.005008          99.96745300292969             \n",
            "Dev Precision:  42.808219%\n",
            "  1268  1077     42001    37/39         95% 0.000033          99.91554260253906             \n",
            "  1298  1103     43001    23/39         59% 0.000127          99.89810180664062             \n",
            "Dev Precision:  43.150685%\n",
            "  1328  1129     44001     9/39         23% 0.003425          99.91319274902344             \n",
            "  1358  1154     45001    34/39         87% 0.000022          99.97702026367188             \n",
            "Dev Precision:  42.294521%\n",
            "  1388  1180     46001    20/39         51% 0.000598          99.9609375             \n",
            "  1419  1206     47001     6/39         15% 0.000021          99.93489837646484             \n",
            "Dev Precision:  42.522831%\n",
            "  1449  1231     48001    31/39         79% 0.003794          99.92439270019531             \n",
            "  1479  1257     49001    17/39         44% 0.000048          99.8851089477539             \n",
            "Dev Precision:  42.579909%\n",
            "  1509  1283     50001     3/39          8% 0.003982          99.86979675292969             \n",
            "  1539  1308     51001    28/39         72% 0.000074          99.9581527709961             \n",
            "Dev Precision:  42.408676%\n",
            "  1569  1334     52001    14/39         36% 0.000011          99.97209930419922             \n",
            "  1599  1359     53001    39/39        100% 0.000004          99.91936492919922             \n",
            "Dev Precision:  42.694064%\n",
            "  1629  1385     54001    25/39         64% 0.000007          99.953125             \n",
            "  1659  1411     55001    11/39         28% 0.000039          99.9289779663086             \n",
            "Dev Precision:  41.894977%\n",
            "Early Stopping. Epoch: 1436, Best Dev Acc: 0.4349315068493151\n",
            "2035\n",
            "Test Precision:  40.667466%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# table 6 output {CNN's row}\n",
        "!python ./BuboQA/relations/train.py  --relation_prediction_mode CNN \\\n",
        "                                     --fix_embed --data_dir ../data/SimpleQuestionNotationRelation \\\n",
        "                                     --batch_size 256 \\\n",
        "                                     --vector_cache ../data/Cache/sq_glove300d.pt "
      ],
      "metadata": {
        "id": "IzWkVwB5L-_b",
        "outputId": "8b0eaf36-516b-49ba-e622-8833a33a4027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IzWkVwB5L-_b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for training\n",
            "Embedding match number 8546 out of 13972\n",
            "Shift model to GPU\n",
            "Namespace(relation_prediction_mode='CNN', cuda=True, gpu=0, epochs=30, batch_size=256, dataset='RelationPrediction', mode='static', lr=0.0001, seed=3435, dev_every=2000, log_every=1000, patience=10, save_path='saved_checkpoints', specify_prefix='id1', output_channel=300, words_dim=300, num_layer=2, rnn_dropout=0.3, input_size=300, hidden_size=300, rnn_fc_dropout=0.3, clip_gradient=0.6, vector_cache='../data/Cache/sq_glove300d.pt', weight_decay=0, cnn_dropout=0.5, train_embed=False, hits=5, data_dir='../data/SimpleQuestionNotationRelation', trained_model='', results_path='results', words_num=13972, rel_label=4236)\n",
            "VOCAB num 13972\n",
            "Train instance 9922\n",
            "Dev instance 1752\n",
            "Test instance 5004\n",
            "Relation Type 4236\n",
            "RelationPrediction(\n",
            "  (embed): Embedding(13972, 300)\n",
            "  (conv1): Conv2d(1, 300, kernel_size=(2, 300), stride=(1, 1), padding=(1, 0))\n",
            "  (conv2): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1), padding=(2, 0))\n",
            "  (conv3): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1), padding=(3, 0))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=900, out_features=4236, bias=True)\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
            "     4     1         1     1/39          3% 8.378649          0.0             \n",
            "    17    26      1001    26/39         67% 4.741943          21.799880981445312             \n",
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "Dev Precision:  27.682648%\n",
            "    30    52      2001    12/39         31% 1.522712          78.54817962646484             \n",
            "    43    77      3001    37/39         95% 0.692873          88.8196792602539             \n",
            "Dev Precision:  31.506849%\n",
            "    56   103      4001    23/39         59% 0.413163          92.96875             \n",
            "    68   129      5001     9/39         23% 0.257943          94.7482681274414             \n",
            "Dev Precision:  33.219178%\n",
            "    81   154      6001    34/39         87% 0.175633          96.38097381591797             \n",
            "    93   180      7001    20/39         51% 0.112310          97.96875             \n",
            "Dev Precision:  34.189498%\n",
            "   106   206      8001     6/39         15% 0.104864          98.828125             \n",
            "   118   231      9001    31/39         79% 0.053773          99.40776062011719             \n",
            "Dev Precision:  35.216895%\n",
            "   131   257     10001    17/39         44% 0.032850          99.58639526367188             \n",
            "   144   283     11001     3/39          8% 0.039726          99.609375             \n",
            "Dev Precision:  35.445205%\n",
            "   156   308     12001    28/39         72% 0.024404          99.88839721679688             \n",
            "   169   334     13001    14/39         36% 0.017168          99.8604965209961             \n",
            "Dev Precision:  35.445205%\n",
            "   181   359     14001    39/39        100% 0.009761          99.88912963867188             \n",
            "   194   385     15001    25/39         64% 0.005600          99.921875             \n",
            "Dev Precision:  35.901826%\n",
            "   206   411     16001    11/39         28% 0.005756          99.82244873046875             \n",
            "   219   436     17001    36/39         92% 0.003682          99.91319274902344             \n",
            "Dev Precision:  35.673516%\n",
            "   232   462     18001    22/39         56% 0.010065          99.94673919677734             \n",
            "   244   488     19001     8/39         21% 0.001596          99.951171875             \n",
            "Dev Precision:  36.415525%\n",
            "   257   513     20001    33/39         85% 0.001499          99.95265197753906             \n",
            "   275   539     21001    19/39         49% 0.004216          99.91776275634766             \n",
            "Dev Precision:  36.757991%\n",
            "   287   565     22001     5/39         13% 0.000705          100.0             \n",
            "   300   590     23001    30/39         77% 0.000524          99.89583587646484             \n",
            "Dev Precision:  36.700913%\n",
            "   312   616     24001    16/39         41% 0.002776          99.90234375             \n",
            "   325   642     25001     2/39          5% 0.006002          99.8046875             \n",
            "Dev Precision:  37.614155%\n",
            "   337   667     26001    27/39         69% 0.000323          99.91319274902344             \n",
            "   350   693     27001    13/39         33% 0.001175          99.93991088867188             \n",
            "Dev Precision:  37.100457%\n",
            "   362   718     28001    38/39         97% 0.004176          99.93832397460938             \n",
            "   375   744     29001    24/39         62% 0.000326          99.951171875             \n",
            "Dev Precision:  36.929224%\n",
            "   388   770     30001    10/39         26% 0.000529          100.0             \n",
            "   400   795     31001    35/39         90% 0.000440          99.95536041259766             \n",
            "Dev Precision:  37.043379%\n",
            "   413   821     32001    21/39         54% 0.000202          99.96279907226562             \n",
            "   425   847     33001     7/39         18% 0.000555          99.94419860839844             \n",
            "Dev Precision:  37.100457%\n",
            "   438   872     34001    32/39         82% 0.000105          99.9755859375             \n",
            "   450   898     35001    18/39         46% 0.000206          99.93489837646484             \n",
            "Dev Precision:  37.500000%\n",
            "   463   924     36001     4/39         10% 0.000077          100.0             \n",
            "   476   949     37001    29/39         74% 0.005939          99.91918182373047             \n",
            "Dev Precision:  37.614155%\n",
            "   488   975     38001    15/39         38% 0.000128          99.94792175292969             \n",
            "   501  1001     39001     1/39          3% 0.000091          100.0             \n",
            "Dev Precision:  37.614155%\n",
            "   513  1026     40001    26/39         67% 0.000088          99.9549331665039             \n",
            "   526  1052     41001    12/39         31% 0.007372          99.96745300292969             \n",
            "Dev Precision:  37.385845%\n",
            "   538  1077     42001    37/39         95% 0.000070          99.92610168457031             \n",
            "   551  1103     43001    23/39         59% 0.000050          99.91508483886719             \n",
            "Dev Precision:  37.557078%\n",
            "   563  1129     44001     9/39         23% 0.003896          99.91319274902344             \n",
            "   576  1154     45001    34/39         87% 0.000054          99.94255828857422             \n",
            "Dev Precision:  38.070776%\n",
            "   589  1180     46001    20/39         51% 0.000060          99.94140625             \n",
            "   601  1206     47001     6/39         15% 0.000380          100.0             \n",
            "Dev Precision:  37.842466%\n",
            "   614  1231     48001    31/39         79% 0.006328          99.92439270019531             \n",
            "   626  1257     49001    17/39         44% 0.000087          99.93106842041016             \n",
            "Dev Precision:  37.842466%\n",
            "   639  1283     50001     3/39          8% 0.003965          99.86979675292969             \n",
            "   651  1308     51001    28/39         72% 0.000056          99.97209930419922             \n",
            "Dev Precision:  38.184932%\n",
            "   664  1334     52001    14/39         36% 0.000033          99.97209930419922             \n",
            "   677  1359     53001    39/39        100% 0.000066          99.96975708007812             \n",
            "Dev Precision:  37.899543%\n",
            "   689  1385     54001    25/39         64% 0.000044          99.9375             \n",
            "   702  1411     55001    11/39         28% 0.000047          99.9289779663086             \n",
            "Dev Precision:  38.527397%\n",
            "   714  1436     56001    36/39         92% 0.005164          99.94574737548828             \n",
            "   727  1462     57001    22/39         56% 0.000049          99.9289779663086             \n",
            "Dev Precision:  38.299087%\n",
            "   739  1488     58001     8/39         21% 0.000041          99.90234375             \n",
            "   752  1513     59001    33/39         85% 0.004683          99.91714477539062             \n",
            "Dev Precision:  38.127854%\n",
            "   764  1539     60001    19/39         49% 0.000030          99.97943878173828             \n",
            "   777  1565     61001     5/39         13% 0.000019          100.0             \n",
            "Dev Precision:  38.242009%\n",
            "   789  1590     62001    30/39         77% 0.000008          99.93489837646484             \n",
            "   802  1616     63001    16/39         41% 0.000109          99.90234375             \n",
            "Dev Precision:  38.184932%\n",
            "   814  1642     64001     2/39          5% 0.000027          100.0             \n",
            "   827  1667     65001    27/39         69% 0.000023          99.92766571044922             \n",
            "Dev Precision:  38.413242%\n",
            "   839  1693     66001    13/39         33% 0.005765          99.90985870361328             \n",
            "   852  1718     67001    38/39         97% 0.002879          99.93832397460938             \n",
            "Dev Precision:  38.013699%\n",
            "   864  1744     68001    24/39         62% 0.007235          99.93489837646484             \n",
            "   877  1770     69001    10/39         26% 0.000009          100.0             \n",
            "Dev Precision:  38.527397%\n",
            "   890  1795     70001    35/39         90% 0.000017          99.921875             \n",
            "   902  1821     71001    21/39         54% 0.000037          99.94419860839844             \n",
            "Dev Precision:  38.242009%\n",
            "   915  1847     72001     7/39         18% 0.000006          99.94419860839844             \n",
            "   927  1872     73001    32/39         82% 0.008186          99.9267578125             \n",
            "Dev Precision:  38.527397%\n",
            "   940  1898     74001    18/39         46% 0.000009          99.97830200195312             \n",
            "   952  1924     75001     4/39         10% 0.003686          100.0             \n",
            "Dev Precision:  38.926941%\n",
            "   965  1949     76001    29/39         74% 0.002711          99.94612121582031             \n",
            "   977  1975     77001    15/39         38% 0.000012          99.84375762939453             \n",
            "Dev Precision:  38.698630%\n",
            "   990  2001     78001     1/39          3% 0.000108          100.0             \n",
            "  1002  2026     79001    26/39         67% 0.000011          99.89483642578125             \n",
            "Dev Precision:  39.098174%\n",
            "  1015  2052     80001    12/39         31% 0.000008          99.96745300292969             \n",
            "  1027  2077     81001    37/39         95% 0.000020          99.89442443847656             \n",
            "Dev Precision:  38.812785%\n",
            "  1040  2103     82001    23/39         59% 0.000696          99.96603393554688             \n",
            "  1053  2129     83001     9/39         23% 0.000033          99.91319274902344             \n",
            "Dev Precision:  39.212329%\n",
            "  1065  2154     84001    34/39         87% 0.000003          99.94255828857422             \n",
            "  1078  2180     85001    20/39         51% 0.000018          99.94140625             \n",
            "Dev Precision:  38.755708%\n",
            "  1090  2206     86001     6/39         15% 0.000004          99.93489837646484             \n",
            "  1103  2231     87001    31/39         79% 0.000013          99.94959259033203             \n",
            "Dev Precision:  39.098174%\n",
            "  1115  2257     88001    17/39         44% 0.000010          99.93106842041016             \n",
            "  1128  2283     89001     3/39          8% 0.000026          100.0             \n",
            "Dev Precision:  39.440639%\n",
            "  1141  2308     90001    28/39         72% 0.000010          99.93025207519531             \n",
            "  1153  2334     91001    14/39         36% 0.000013          99.94419860839844             \n",
            "Dev Precision:  39.440639%\n",
            "  1166  2359     92001    39/39        100% 0.000004          99.95967864990234             \n",
            "  1178  2385     93001    25/39         64% 0.000005          99.921875             \n",
            "Dev Precision:  38.698630%\n",
            "  1190  2411     94001    11/39         28% 0.002597          99.9289779663086             \n",
            "  1203  2436     95001    36/39         92% 0.003409          99.93489837646484             \n",
            "Dev Precision:  38.984018%\n",
            "  1215  2462     96001    22/39         56% 0.000012          99.94673919677734             \n",
            "  1228  2488     97001     8/39         21% 0.000008          99.951171875             \n",
            "Dev Precision:  39.269406%\n",
            "  1240  2513     98001    33/39         85% 0.000002          99.9408187866211             \n",
            "  1253  2539     99001    19/39         49% 0.000003          99.93832397460938             \n",
            "Dev Precision:  38.984018%\n",
            "  1265  2565    100001     5/39         13% 0.002866          99.84375             \n",
            "  1278  2590    101001    30/39         77% 0.005773          99.90885925292969             \n",
            "Dev Precision:  39.840183%\n",
            "  1290  2616    102001    16/39         41% 0.000007          100.0             \n",
            "  1303  2642    103001     2/39          5% 0.004634          99.8046875             \n",
            "Dev Precision:  38.984018%\n",
            "  1315  2667    104001    27/39         69% 0.000003          99.94213104248047             \n",
            "  1328  2693    105001    13/39         33% 0.000004          99.87981414794922             \n",
            "Dev Precision:  39.269406%\n",
            "  1341  2718    106001    38/39         97% 0.000020          99.94860076904297             \n",
            "  1353  2744    107001    24/39         62% 0.000004          99.91862487792969             \n",
            "Dev Precision:  39.554795%\n",
            "  1366  2770    108001    10/39         26% 0.000002          100.0             \n",
            "  1378  2795    109001    35/39         90% 0.000005          99.96652221679688             \n",
            "Dev Precision:  39.497717%\n",
            "  1391  2821    110001    21/39         54% 0.000007          99.98139953613281             \n",
            "  1403  2847    111001     7/39         18% 0.000046          99.94419860839844             \n",
            "Dev Precision:  39.726027%\n",
            "  1416  2872    112001    32/39         82% 0.000007          99.9755859375             \n",
            "  1428  2898    113001    18/39         46% 0.000002          99.95659637451172             \n",
            "Dev Precision:  39.554795%\n",
            "  1441  2924    114001     4/39         10% 0.005437          99.90234375             \n",
            "  1453  2949    115001    29/39         74% 0.000001          99.93264770507812             \n",
            "Dev Precision:  39.668950%\n",
            "  1466  2975    116001    15/39         38% 0.000013          99.94792175292969             \n",
            "  1478  3001    117001     1/39          3% 0.000001          100.0             \n",
            "Dev Precision:  39.440639%\n",
            "  1491  3026    118001    26/39         67% 0.005962          99.92488098144531             \n",
            "  1504  3052    119001    12/39         31% 0.000002          99.90234375             \n",
            "Dev Precision:  39.212329%\n",
            "  1516  3077    120001    37/39         95% 0.000002          99.92610168457031             \n",
            "  1529  3103    121001    23/39         59% 0.000018          99.94905090332031             \n",
            "Dev Precision:  39.440639%\n",
            "  1541  3129    122001     9/39         23% 0.006629          99.91319274902344             \n",
            "  1554  3154    123001    34/39         87% 0.000002          99.93106842041016             \n",
            "Dev Precision:  39.611872%\n",
            "Early Stopping. Epoch: 3180, Best Dev Acc: 0.3984018264840183\n",
            "1910\n",
            "Test Precision:  38.169464%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "HnIW58cTag2i",
        "outputId": "c20edd42-c942-4587-8c4a-7c323a4ef80d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HnIW58cTag2i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeOceanBERTQA/code/CodeOceanBERTQA/code/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e444ba",
      "metadata": {
        "id": "d8e444ba",
        "outputId": "865ee318-45e2-4f69-908a-907f47ba2c58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeOceanBERTQA/code/src\n",
            "2023-03-17 13:18:53.257056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-17 13:18:54.619821: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 13:18:54.619963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-17 13:18:54.619987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:root:Train Dataset Contains 75682 Samples.\n",
            "INFO:root:Valid Dataset Contains 10806 Samples.\n",
            "INFO:root:Test Dataset Contains 21615 Samples.\n",
            "Train Epoch Number 1:   0% 0/379 [00:09<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CodeOceanBERTQA/code/src/train.py\", line 439, in <module>\n",
            "    tl.train(train_dataloader, valid_dataloader, loss)\n",
            "  File \"/content/CodeOceanBERTQA/code/src/train.py\", line 239, in train\n",
            "    logits = self.model(X) \n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/CodeOceanBERTQA/code/src/train.py\", line 92, in forward\n",
            "    bert_outputs = self.bert(x, attention_mask=mask, output_hidden_states=False)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\", line 1020, in forward\n",
            "    encoder_outputs = self.encoder(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\", line 610, in forward\n",
            "    layer_outputs = layer_module(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\", line 537, in forward\n",
            "    layer_output = apply_chunking_to_forward(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/pytorch_utils.py\", line 248, in apply_chunking_to_forward\n",
            "    return forward_fn(*input_tensors)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\", line 550, in feed_forward_chunk\n",
            "    layer_output = self.output(intermediate_output, attention_output)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\", line 462, in forward\n",
            "    hidden_states = self.dense(hidden_states)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# table 7 & 8 & 9 & 10 output\n",
        "\n",
        "\n",
        "%cd /content/CodeOceanBERTQA/code/src\n",
        "# model types : [MultiDepthNodeEdgeDetector, BertLSTMCRF, BertCNN, NodeEdgeDetector]\n",
        "# cross validation: [True, False]\n",
        "!python train.py NodeEdgeDetector sq valid\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7d750b14",
      "metadata": {
        "id": "7d750b14",
        "outputId": "b583dd55-83a3-4cb3-97e6-bd327c9b8017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeOceanBERTQA/code/src\n",
            "2023-03-18 21:34:43.668026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-18 21:34:44.678537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-18 21:34:44.678656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-18 21:34:44.678678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "INFO:root:\n",
            "\n",
            "############# Fold Number 1 #############\n",
            "\n",
            "\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:root:Train Dataset Contains 10630 Samples.\n",
            "INFO:root:Valid Dataset Contains 1876 Samples.\n",
            "INFO:root:Test Dataset Contains 4169 Samples.\n",
            "Train Epoch Number 1: 100% 54/54 [00:33<00:00,  1.63it/s]\n",
            "INFO:root:Epoch number: 1 Train Loss is equal: 360.4850769042969\n",
            "Eval Epoch Number 1: 100% 10/10 [00:01<00:00,  5.27it/s]\n",
            "INFO:root:Epoch number: 1 Eval Loss is equal: 160.9254608154297\n",
            "Train Epoch Number 2: 100% 54/54 [00:32<00:00,  1.65it/s]\n",
            "INFO:root:Epoch number: 2 Train Loss is equal: 151.3327178955078\n",
            "Eval Epoch Number 2: 100% 10/10 [00:01<00:00,  5.67it/s]\n",
            "INFO:root:Epoch number: 2 Eval Loss is equal: 79.55394744873047\n",
            "Train Epoch Number 3: 100% 54/54 [00:32<00:00,  1.68it/s]\n",
            "INFO:root:Epoch number: 3 Train Loss is equal: 82.98674774169922\n",
            "Eval Epoch Number 3: 100% 10/10 [00:01<00:00,  5.54it/s]\n",
            "INFO:root:Epoch number: 3 Eval Loss is equal: 48.40277862548828\n",
            "Train Epoch Number 4: 100% 54/54 [00:32<00:00,  1.64it/s]\n",
            "INFO:root:Epoch number: 4 Train Loss is equal: 61.397953033447266\n",
            "Eval Epoch Number 4: 100% 10/10 [00:01<00:00,  5.59it/s]\n",
            "INFO:root:Epoch number: 4 Eval Loss is equal: 45.91343688964844\n",
            "Train Epoch Number 5: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 5 Train Loss is equal: 54.98072814941406\n",
            "Eval Epoch Number 5: 100% 10/10 [00:01<00:00,  5.56it/s]\n",
            "INFO:root:Epoch number: 5 Eval Loss is equal: 30.313175201416016\n",
            "Train Epoch Number 6: 100% 54/54 [00:32<00:00,  1.67it/s]\n",
            "INFO:root:Epoch number: 6 Train Loss is equal: 40.17311477661133\n",
            "Eval Epoch Number 6: 100% 10/10 [00:01<00:00,  5.58it/s]\n",
            "INFO:root:Epoch number: 6 Eval Loss is equal: 27.564849853515625\n",
            "Train Epoch Number 7: 100% 54/54 [00:32<00:00,  1.64it/s]\n",
            "INFO:root:Epoch number: 7 Train Loss is equal: 34.18832015991211\n",
            "Eval Epoch Number 7: 100% 10/10 [00:01<00:00,  5.56it/s]\n",
            "INFO:root:Epoch number: 7 Eval Loss is equal: 25.767847061157227\n",
            "Train Epoch Number 8: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 8 Train Loss is equal: 31.5096378326416\n",
            "Eval Epoch Number 8: 100% 10/10 [00:01<00:00,  5.59it/s]\n",
            "INFO:root:Epoch number: 8 Eval Loss is equal: 24.740638732910156\n",
            "Predicting ...: 100% 42/42 [00:04<00:00, 10.39it/s]\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9838204869768182, 0.9888035828534869, 0.9788873640874063\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9856763925664748, 0.9857736810243404, 0.985579123309994\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9680978651954906\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9872555938395118, 0.990174036139562, 0.9843543046357616\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9916354478871569, 0.9935573221852902, 0.989720994338409\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9513072679299592\n",
            "INFO:root:\n",
            "\n",
            "############# Fold Number 2 #############\n",
            "\n",
            "\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "INFO:root:Train Dataset Contains 10630 Samples.\n",
            "INFO:root:Valid Dataset Contains 1876 Samples.\n",
            "INFO:root:Test Dataset Contains 4169 Samples.\n",
            "Train Epoch Number 1: 100% 54/54 [00:31<00:00,  1.69it/s]\n",
            "INFO:root:Epoch number: 1 Train Loss is equal: 339.5882568359375\n",
            "Eval Epoch Number 1: 100% 10/10 [00:01<00:00,  5.50it/s]\n",
            "INFO:root:Epoch number: 1 Eval Loss is equal: 130.35610961914062\n",
            "Train Epoch Number 2: 100% 54/54 [00:32<00:00,  1.67it/s]\n",
            "INFO:root:Epoch number: 2 Train Loss is equal: 120.47063446044922\n",
            "Eval Epoch Number 2: 100% 10/10 [00:01<00:00,  5.55it/s]\n",
            "INFO:root:Epoch number: 2 Eval Loss is equal: 53.2425537109375\n",
            "Train Epoch Number 3: 100% 54/54 [00:32<00:00,  1.68it/s]\n",
            "INFO:root:Epoch number: 3 Train Loss is equal: 65.55562591552734\n",
            "Eval Epoch Number 3: 100% 10/10 [00:01<00:00,  5.57it/s]\n",
            "INFO:root:Epoch number: 3 Eval Loss is equal: 35.836448669433594\n",
            "Train Epoch Number 4: 100% 54/54 [00:31<00:00,  1.69it/s]\n",
            "INFO:root:Epoch number: 4 Train Loss is equal: 49.53445053100586\n",
            "Eval Epoch Number 4: 100% 10/10 [00:01<00:00,  5.58it/s]\n",
            "INFO:root:Epoch number: 4 Eval Loss is equal: 28.916431427001953\n",
            "Train Epoch Number 5: 100% 54/54 [00:31<00:00,  1.69it/s]\n",
            "INFO:root:Epoch number: 5 Train Loss is equal: 39.09537887573242\n",
            "Eval Epoch Number 5: 100% 10/10 [00:01<00:00,  5.59it/s]\n",
            "INFO:root:Epoch number: 5 Eval Loss is equal: 26.481674194335938\n",
            "Train Epoch Number 6: 100% 54/54 [00:32<00:00,  1.67it/s]\n",
            "INFO:root:Epoch number: 6 Train Loss is equal: 33.61482620239258\n",
            "Eval Epoch Number 6: 100% 10/10 [00:01<00:00,  5.53it/s]\n",
            "INFO:root:Epoch number: 6 Eval Loss is equal: 22.794025421142578\n",
            "Train Epoch Number 7: 100% 54/54 [00:31<00:00,  1.69it/s]\n",
            "INFO:root:Epoch number: 7 Train Loss is equal: 29.783706665039062\n",
            "Eval Epoch Number 7: 100% 10/10 [00:01<00:00,  5.54it/s]\n",
            "INFO:root:Epoch number: 7 Eval Loss is equal: 22.43631935119629\n",
            "Train Epoch Number 8: 100% 54/54 [00:32<00:00,  1.67it/s]\n",
            "INFO:root:Epoch number: 8 Train Loss is equal: 28.293787002563477\n",
            "Eval Epoch Number 8: 100% 10/10 [00:01<00:00,  5.52it/s]\n",
            "INFO:root:Epoch number: 8 Eval Loss is equal: 22.23368263244629\n",
            "Predicting ...: 100% 42/42 [00:04<00:00, 10.16it/s]\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9850474301945442, 0.9876410531972059, 0.9824673936283943\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.987927384895603, 0.9890319516308962, 0.9868252826036467\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9702566562724874\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9884963023829089, 0.9930658741951461, 0.9839685915262555\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9931645744759134, 0.9948011970439411, 0.9915333281258042\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9606620292636123\n",
            "INFO:root:\n",
            "\n",
            "############# Fold Number 3 #############\n",
            "\n",
            "\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "INFO:root:Train Dataset Contains 10630 Samples.\n",
            "INFO:root:Valid Dataset Contains 1876 Samples.\n",
            "INFO:root:Test Dataset Contains 4169 Samples.\n",
            "Train Epoch Number 1: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 1 Train Loss is equal: 353.8774108886719\n",
            "Eval Epoch Number 1: 100% 10/10 [00:01<00:00,  5.39it/s]\n",
            "INFO:root:Epoch number: 1 Eval Loss is equal: 143.4149627685547\n",
            "Train Epoch Number 2: 100% 54/54 [00:32<00:00,  1.65it/s]\n",
            "INFO:root:Epoch number: 2 Train Loss is equal: 134.63487243652344\n",
            "Eval Epoch Number 2: 100% 10/10 [00:01<00:00,  5.45it/s]\n",
            "INFO:root:Epoch number: 2 Eval Loss is equal: 68.89698028564453\n",
            "Train Epoch Number 3: 100% 54/54 [00:32<00:00,  1.67it/s]\n",
            "INFO:root:Epoch number: 3 Train Loss is equal: 80.72419738769531\n",
            "Eval Epoch Number 3: 100% 10/10 [00:01<00:00,  5.40it/s]\n",
            "INFO:root:Epoch number: 3 Eval Loss is equal: 45.278717041015625\n",
            "Train Epoch Number 4: 100% 54/54 [00:32<00:00,  1.65it/s]\n",
            "INFO:root:Epoch number: 4 Train Loss is equal: 58.025733947753906\n",
            "Eval Epoch Number 4: 100% 10/10 [00:01<00:00,  5.41it/s]\n",
            "INFO:root:Epoch number: 4 Eval Loss is equal: 33.00303268432617\n",
            "Train Epoch Number 5: 100% 54/54 [00:32<00:00,  1.68it/s]\n",
            "INFO:root:Epoch number: 5 Train Loss is equal: 44.74703598022461\n",
            "Eval Epoch Number 5: 100% 10/10 [00:01<00:00,  5.39it/s]\n",
            "INFO:root:Epoch number: 5 Eval Loss is equal: 30.333911895751953\n",
            "Train Epoch Number 6: 100% 54/54 [00:32<00:00,  1.64it/s]\n",
            "INFO:root:Epoch number: 6 Train Loss is equal: 37.1954345703125\n",
            "Eval Epoch Number 6: 100% 10/10 [00:01<00:00,  5.43it/s]\n",
            "INFO:root:Epoch number: 6 Eval Loss is equal: 24.294645309448242\n",
            "Train Epoch Number 7: 100% 54/54 [00:32<00:00,  1.67it/s]\n",
            "INFO:root:Epoch number: 7 Train Loss is equal: 32.68169403076172\n",
            "Eval Epoch Number 7: 100% 10/10 [00:01<00:00,  5.38it/s]\n",
            "INFO:root:Epoch number: 7 Eval Loss is equal: 33.16080856323242\n",
            "Train Epoch Number 8: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 8 Train Loss is equal: 36.38935470581055\n",
            "Eval Epoch Number 8: 100% 10/10 [00:01<00:00,  5.40it/s]\n",
            "INFO:root:Epoch number: 8 Eval Loss is equal: 25.63102149963379\n",
            "Predicting ...: 100% 42/42 [00:04<00:00, 10.41it/s]\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9855009971433191, 0.9871504157218443, 0.9838570813603099\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9874750656090459, 0.9874923376242638, 0.9874577941980197\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9707363876229311\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9892144303483615, 0.9931131762363093, 0.9853461760105375\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9929403162369455, 0.9953211915612967, 0.9905708041591951\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9573039098105062\n",
            "INFO:root:\n",
            "\n",
            "############# Fold Number 4 #############\n",
            "\n",
            "\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "INFO:root:Train Dataset Contains 10630 Samples.\n",
            "INFO:root:Valid Dataset Contains 1877 Samples.\n",
            "INFO:root:Test Dataset Contains 4168 Samples.\n",
            "Train Epoch Number 1: 100% 54/54 [00:32<00:00,  1.65it/s]\n",
            "INFO:root:Epoch number: 1 Train Loss is equal: 340.0126953125\n",
            "Eval Epoch Number 1: 100% 10/10 [00:01<00:00,  5.02it/s]\n",
            "INFO:root:Epoch number: 1 Eval Loss is equal: 118.6059799194336\n",
            "Train Epoch Number 2: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 2 Train Loss is equal: 109.09842681884766\n",
            "Eval Epoch Number 2: 100% 10/10 [00:01<00:00,  5.05it/s]\n",
            "INFO:root:Epoch number: 2 Eval Loss is equal: 50.68041229248047\n",
            "Train Epoch Number 3: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 3 Train Loss is equal: 64.09501647949219\n",
            "Eval Epoch Number 3: 100% 10/10 [00:01<00:00,  5.02it/s]\n",
            "INFO:root:Epoch number: 3 Eval Loss is equal: 33.753021240234375\n",
            "Train Epoch Number 4: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 4 Train Loss is equal: 47.27070236206055\n",
            "Eval Epoch Number 4: 100% 10/10 [00:01<00:00,  5.06it/s]\n",
            "INFO:root:Epoch number: 4 Eval Loss is equal: 32.001522064208984\n",
            "Train Epoch Number 5: 100% 54/54 [00:32<00:00,  1.65it/s]\n",
            "INFO:root:Epoch number: 5 Train Loss is equal: 40.18248748779297\n",
            "Eval Epoch Number 5: 100% 10/10 [00:01<00:00,  5.06it/s]\n",
            "INFO:root:Epoch number: 5 Eval Loss is equal: 29.78462791442871\n",
            "Train Epoch Number 6: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 6 Train Loss is equal: 35.084136962890625\n",
            "Eval Epoch Number 6: 100% 10/10 [00:01<00:00,  5.05it/s]\n",
            "INFO:root:Epoch number: 6 Eval Loss is equal: 29.913089752197266\n",
            "Train Epoch Number 7: 100% 54/54 [00:31<00:00,  1.69it/s]\n",
            "INFO:root:Epoch number: 7 Train Loss is equal: 31.300704956054688\n",
            "Eval Epoch Number 7: 100% 10/10 [00:01<00:00,  5.03it/s]\n",
            "INFO:root:Epoch number: 7 Eval Loss is equal: 28.13490104675293\n",
            "Train Epoch Number 8: 100% 54/54 [00:32<00:00,  1.66it/s]\n",
            "INFO:root:Epoch number: 8 Train Loss is equal: 29.315444946289062\n",
            "Eval Epoch Number 8: 100% 10/10 [00:01<00:00,  5.04it/s]\n",
            "INFO:root:Epoch number: 8 Eval Loss is equal: 24.39266014099121\n",
            "Predicting ...: 100% 42/42 [00:03<00:00, 10.66it/s]\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.987953080418472, 0.9922521757588623, 0.9836910774410774\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.989928033018357, 0.9914226861851052, 0.9884378796986762\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9736021118310535\n",
            "INFO:root:Dataset-wide F1, precision and recall:\n",
            "INFO:root:0.9910162367097998, 0.993226499256567, 0.9888157894736842\n",
            "INFO:root:Averaged F1, precision and recall:\n",
            "INFO:root:0.9940555254333875, 0.9955477104469431, 0.99256780687323\n",
            "INFO:root:Span accuracy\n",
            "INFO:root:0.9637715930902111\n",
            "\n",
            "Entity Span Accuracy: 0.9637715930902111\n",
            "Relation Span Accuracy: 0.9736021118310535\n",
            "Entity (Precision, Recall, F1, F1*) [[0.9855805  0.98896181 0.98222573]\n",
            " [0.98775172 0.98843016 0.98707502]]\n",
            "Relation (Precision, Recall, F1, F1*) [[0.98899564 0.9923949  0.98562122]\n",
            " [0.99294897 0.99480686 0.99109823]]\n"
          ]
        }
      ],
      "source": [
        "%cd /content/CodeOceanBERTQA/code/src\n",
        "# model types : [MultiDepthNodeEdgeDetector, BertLSTMCRF, BertCNN, NodeEdgeDetector]\n",
        "# cross validation: [True, False]\n",
        "!python train.py BertLSTMCRF rsq test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BaKtbZnXaVYV"
      },
      "id": "BaKtbZnXaVYV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}