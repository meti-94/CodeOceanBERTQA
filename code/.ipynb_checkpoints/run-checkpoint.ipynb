{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf91d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f00800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Bertified data exists\n",
    "if not os.path.isfile('../data/Bertified/entities.npy'):\n",
    "    reverb_lines = read_reverb('../data/Reverb1.1/reverb_wikipedia_tuples-1.1.txt')\n",
    "    questions = pd.read_excel('../data/ReverbSQA/Final_Sheet_990824.xlsx', sheet_name=1, engine='openpyxl')\n",
    "    index = get_tuple_frequency(reverb_lines, questions)\n",
    "    index[index['Frequency']<10].to_excel('../data/ProcessedQuestions/normalized_questions.xlsx')\n",
    "    combine_with_reverb(questions_path='../data/ProcessedQuestions/normalized_questions.xlsx', \n",
    "                    reverb_path='../data/Reverb1.1/reverb_wikipedia_tuples-1.1.txt')\n",
    "    create_bertified_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4740e484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>('Oracle Corporation', 'completed the acquisit...</td>\n",
       "      <td>What Oracle Corporation completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>('Lee', 'was elected mayor of', 'Chapel Hill')</td>\n",
       "      <td>Who was elected mayor of Chapel Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>('The WEC', 'was first organized in', '1990')</td>\n",
       "      <td>What was first organized in 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>('The Wall Street Journal', 'reported in', 'Se...</td>\n",
       "      <td>when did The Wall Street Journal report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>('Clarendon Hills', 'is an affluent village in...</td>\n",
       "      <td>What village is in DuPage County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>('Second-parent adoptions', 'were designed for...</td>\n",
       "      <td>for whom were Second-parent adoptions designed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 triple  \\\n",
       "6196  ('Oracle Corporation', 'completed the acquisit...   \n",
       "7399     ('Lee', 'was elected mayor of', 'Chapel Hill')   \n",
       "6300      ('The WEC', 'was first organized in', '1990')   \n",
       "4868  ('The Wall Street Journal', 'reported in', 'Se...   \n",
       "9739  ('Clarendon Hills', 'is an affluent village in...   \n",
       "5658  ('Second-parent adoptions', 'were designed for...   \n",
       "\n",
       "                                             Question  \n",
       "6196              What Oracle Corporation completed    \n",
       "7399             Who was elected mayor of Chapel Hill  \n",
       "6300                 What was first organized in 1990  \n",
       "4868         when did The Wall Street Journal report   \n",
       "9739                 What village is in DuPage County  \n",
       "5658  for whom were Second-parent adoptions designed   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table 1 output \n",
    "pd.read_excel('../data/Intermediate/train.xlsx').sample(6)[['triple', 'Question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b66aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Triples\t:\t407236\n",
      "#Relations\t:\t101977\n",
      "#Entity 1\t:\t182329\n",
      "#Entity 2\t:\t156166\n",
      "Total Unique Entities\t:\t304853\n",
      "Vocabulary Size\t:\t148953\n"
     ]
    }
   ],
   "source": [
    "# table 2 output\n",
    "df = pd.read_csv(r'../data/Reverb1.1/reverb_wikipedia_tuples-1.1.txt', sep='\\t', header=None)\n",
    "reverb_columns_name = ['ExID', 'arg1', 'rel', 'arg2', 'narg1', 'nrel', 'narg2', 'csents', 'conf', 'urls']\n",
    "df.columns = reverb_columns_name\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f'#Triples\\t:\\t{len(df)}')\n",
    "print(f'#Relations\\t:\\t{len(df[\"rel\"].unique())}')\n",
    "print(f'#Entity 1\\t:\\t{len(df[\"arg1\"].unique())}')\n",
    "print(f'#Entity 2\\t:\\t{len(df[\"arg2\"].unique())}')\n",
    "print(f'Total Unique Entities\\t:\\t{len(set(df[\"arg1\"].unique().tolist()+df[\"arg2\"].unique().tolist()))}')\n",
    "vocab = df[\"arg1\"].unique().tolist()+df[\"arg2\"].unique().tolist()+df[\"rel\"].unique().tolist()\n",
    "vocab = list(map(lambda x:x.split(), vocab))\n",
    "vocab = [item for sublist in vocab for item in sublist]\n",
    "print(f'Vocabulary Size\\t:\\t{len(set(vocab))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f11e164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training ***\n",
      "Number of Questions\t:\t9921\n",
      "Entity 1\t:\t6549\n",
      "Entity 2\t:\t5971\n",
      "Relations\t:\t4568\n",
      "Total Unique Entities\t:\t12155\n",
      "Unique Words\t:\t10123\n",
      "\n",
      "*** Validation ***\n",
      "Number of Questions\t:\t1751\n",
      "Entity 1\t:\t1624\n",
      "Entity 2\t:\t1566\n",
      "Relations\t:\t1297\n",
      "Total Unique Entities\t:\t3147\n",
      "Unique Words\t:\t2958\n",
      "\n",
      "*** Test ***\n",
      "Number of Questions\t:\t5003\n",
      "Entity 1\t:\t4064\n",
      "Entity 2\t:\t3827\n",
      "Relations\t:\t2939\n",
      "Total Unique Entities\t:\t7702\n",
      "Unique Words\t:\t6314\n"
     ]
    }
   ],
   "source": [
    "# table 3 output\n",
    "train_df = pd.read_excel('../data/Intermediate/train.xlsx'); valid_df = pd.read_excel('../data/Intermediate/valid.xlsx'); test_df = pd.read_excel('../data/Intermediate/test.xlsx')\n",
    "\n",
    "\n",
    "def get_unique_ent_rel(dataframe):\n",
    "    arg1 = [eval(item)[0] for item in dataframe['triple'].to_list()]\n",
    "    arg2 = [eval(item)[2] for item in dataframe['triple'].to_list()]\n",
    "    rel = [eval(item)[1] for item in dataframe['triple'].to_list()]\n",
    "    print(f'Number of Questions\\t:\\t{len(dataframe)}')\n",
    "    print(f'Entity 1\\t:\\t{len(set(arg1))}')\n",
    "    print(f'Entity 2\\t:\\t{len(set(arg2))}')\n",
    "    print(f'Relations\\t:\\t{len(set(rel))}')\n",
    "    print(f'Total Unique Entities\\t:\\t{len(set(arg1+arg2))}')\n",
    "    tokenizer = lambda string:string.strip().lower().split()\n",
    "    tokenized_questions = dataframe['Question'].astype(str).apply(tokenizer).to_list()\n",
    "    flatten_tokenized_questions = [item for sublist in tokenized_questions for item in sublist]\n",
    "    print(f'Unique Words\\t:\\t{len(set(flatten_tokenized_questions))}')\n",
    "\n",
    "print(\"*** Training ***\")\n",
    "get_unique_ent_rel(train_df)\n",
    "print(\"\\n*** Validation ***\")\n",
    "get_unique_ent_rel(valid_df)\n",
    "print(\"\\n*** Test ***\")\n",
    "get_unique_ent_rel(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25a1f3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding match number 8546 out of 13972\n",
      "Namespace(batch_size=256, clip_gradient=0.6, cuda=False, data_dir='../data/SimpleQuestionNotationEntity', dataset='EntityDetection', dev_every=2000, entity_detection_mode='GRU', epochs=30, gpu=-1, hidden_size=300, hits=100, input_size=300, label=4, log_every=1000, lr=0.0001, num_layer=2, patience=10, results_path='query_text', rnn_dropout=0.3, rnn_fc_dropout=0.3, save_path='saved_checkpoints', seed=3435, specify_prefix='id1', train_embed=False, trained_model='', vector_cache='../data/Cache/sq_glove300d.pt', weight_decay=0, words_dim=300, words_num=13972)\n",
      "VOCAB num 13972\n",
      "Train instance 9921\n",
      "Dev instance 1751\n",
      "Test instance 5003\n",
      "Entity Type 4\n",
      "EntityDetection(\n",
      "  (embed): Embedding(13972, 300)\n",
      "  (gru): GRU(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (hidden2tag): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=600, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "     1     1         1     1/39          3% 1.575895          0.0             \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"./BuboQA/entities/train.py\", line 138, in <module>\n",
      "    loss.backward()\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# table 5 output {GRU or LSTM}\n",
    "!python ./BuboQA/entities/train.py  --entity_detection_mode GRU \\\n",
    "                                    --fix_embed --data_dir ../data/SimpleQuestionNotationEntity \\\n",
    "                                    --batch_size 256 \\\n",
    "                                    --vector_cache ../data/Cache/sq_glove300d.pt \\\n",
    "                                    --no_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e444ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding match number 8546 out of 13972\n",
      "Namespace(batch_size=32, clip_gradient=0.6, cnn_dropout=0.5, cuda=False, data_dir='../data/SimpleQuestionNotationRelation', dataset='RelationPrediction', dev_every=2000, epochs=30, gpu=-1, hidden_size=300, hits=5, input_size=300, log_every=1000, lr=0.0001, mode='static', num_layer=2, output_channel=300, patience=10, rel_label=4236, relation_prediction_mode='GRU', results_path='results', rnn_dropout=0.3, rnn_fc_dropout=0.3, save_path='saved_checkpoints', seed=3435, specify_prefix='id1', train_embed=False, trained_model='', vector_cache='../data/Cache/sq_glove300d.pt', weight_decay=0, words_dim=300, words_num=13972)\n",
      "VOCAB num 13972\n",
      "Train instance 9922\n",
      "Dev instance 1752\n",
      "Test instance 5004\n",
      "Relation Type 4236\n",
      "RelationPrediction(\n",
      "  (embed): Embedding(13972, 300)\n",
      "  (gru): GRU(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (hidden2tag): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
      "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=600, out_features=4236, bias=True)\n",
      "  )\n",
      ")\n",
      "  Time Epoch Iteration Progress    (%Epoch)   Loss   Dev/Loss     Accuracy  Dev/Accuracy\n",
      "     0     1         1     1/311         0% 8.462593          0.0             \n",
      "   140     4      1001    68/311        22% 5.536623          21.737133026123047             \n",
      "/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "Dev Precision:  26.997717%\n",
      "   272     7      2001   135/311        43% 3.198482          54.907405853271484             \n",
      "   403    10      3001   202/311        65% 1.138782          83.41584014892578             \n",
      "Dev Precision:  33.219178%\n",
      "   533    13      4001   269/311        86% 0.565428          91.25232696533203             \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"./BuboQA/relations/train.py\", line 125, in <module>\n",
      "    scores = model(batch)\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/code/BuboQA/relations/relation_prediction.py\", line 89, in forward\n",
      "    tags = self.hidden2tag(ht[-2:].transpose(0, 1).contiguous().view(batch_size, -1))\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/d/git/CodeOceanBERTQA/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# table 6 output {GRU or LSTM}\n",
    "!python ./BuboQA/relations/train.py  --fix_embed --relation_prediction_mode GRU \\\n",
    "                  --data_dir ../data/SimpleQuestionNotationRelation \\\n",
    "                  --vector_cache ../data/Cache/sq_glove300d.pt \\\n",
    "                  --no_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d750b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
